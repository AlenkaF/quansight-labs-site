<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Quansight Labs (Posts about Open-Source)</title><link>https://labs.quansight.org/</link><description></description><atom:link href="https://labs.quansight.org/categories/open-source.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2021 &lt;a href="mailto:info@quansight.com"&gt;Quansight Labs Team&lt;/a&gt; </copyright><lastBuildDate>Sat, 21 Aug 2021 10:46:04 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Is GitHub Actions suitable for running benchmarks?</title><link>https://labs.quansight.org/blog/2021/08/github-actions-benchmarks/</link><dc:creator>Jaime Rodríguez-Guerra</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;img alt="Reliability of benchmarks in GitHub Actions. This 2D plot shows a 16-day timeseries in the X axis.
  Each data point in the X axis corresponds to a cloud of 75 measurements (one per benchmark test).
  The y-axis spread of each cloud corresponds to the performance ratio. Ideal measurements would have
  a performance ratio of 1.0, since both runs returned the exact same performance. In practice this
  does not happen and we can observe ratios between 0.6 and 1.5. This plot shows that while there
  is an observable y-spread, it is small enough to be considered sensitive to performance
  regressions of more than 50%." src="https://labs.quansight.org/images/2021/08/github-actions-benchmark.png"&gt;&lt;/p&gt;
&lt;p&gt;Benchmarking software is a tricky business. For robust results, you need dedicated
hardware that only runs the benchmarking suite under controlled conditions. No other
processes! No OS updates! Nothing else! Even then, you might find out that CPU throttling,
thermal regulation and other issues can introduce noise in your measurements.&lt;/p&gt;
&lt;p&gt;So, how are we even trying to do it on a CI provider like GitHub Actions?
Every job runs in a separate VM instance with frequent updates and shared resources. It
looks like it would just be a very expensive random number generator.&lt;/p&gt;
&lt;p&gt;Well, it turns out that there &lt;em&gt;is&lt;/em&gt; a sensible way to do it: &lt;strong&gt;relative benchmarking&lt;/strong&gt;.
And we know it works because we have been collecting stability data points for several
weeks.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://labs.quansight.org/blog/2021/08/github-actions-benchmarks/"&gt;Read more…&lt;/a&gt; (13 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>continuous-integration</category><category>github-actions</category><category>Open-Source</category><category>performance</category><guid>https://labs.quansight.org/blog/2021/08/github-actions-benchmarks/</guid><pubDate>Wed, 18 Aug 2021 00:01:00 GMT</pubDate></item><item><title>Rethinking Jupyter Interactive Documentation</title><link>https://labs.quansight.org/blog/2021/05/rethinking-jupyter-documentation/</link><dc:creator>Matthias Bussonnier</dc:creator><description>&lt;div&gt;&lt;p&gt;Jupyter Notebook first release was 8 years ago – under the IPython Notebook
name at the time. Even if notebooks were not invented by Jupyter; they were
definitely democratized by it. Being Web powered allowed development of many
changes in the Datascience world. Objects now often expose rich representation; from
Pandas dataframes with as html tables, to more recent &lt;a href="https://github.com/scikit-learn/scikit-learn/pull/14180"&gt;Scikit-learn model&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Today I want to look into a topic that has not evolved much since, and I believe
could use an upgrade. Accessing interactive Documentation when in a Jupyter
session, and what it could become. At the end I'll link to my current prototype
if you are adventurous.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://labs.quansight.org/blog/2021/05/rethinking-jupyter-documentation/"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>documentation</category><category>Open-Source</category><category>Python</category><guid>https://labs.quansight.org/blog/2021/05/rethinking-jupyter-documentation/</guid><pubDate>Fri, 07 May 2021 00:01:00 GMT</pubDate></item><item><title>Making SciPy's Image Interpolation Consistent and Well Documented</title><link>https://labs.quansight.org/blog/2021/01/scipy-ndimage-interpolation/</link><dc:creator>Gregory Lee</dc:creator><description>&lt;div&gt;&lt;h2&gt;SciPy n-dimensional Image Processing&lt;/h2&gt;
&lt;p&gt;SciPy's ndimage module provides a powerful set of general, n-dimensional image processing operations, categorized into areas such as filtering, interpolation and morphology. Traditional image processing deals with 2D arrays of pixels, possibly with an additional array dimension of size 3 or 4 to represent color channel and transparency information. However, there are many scientific applications where we may want to work with more general arrays such as the 3D volumetric images produced by medical imaging methods like computed tomography (CT) or magnetic resonance imaging (MRI) or biological imaging approaches such as light sheet microscopy. Aside from spatial axes, such data may have additional axes representing other quantities such as time, color, spectral frequency or different contrasts. Functions in ndimage have been implemented in a general n-dimensional manner so that they can be applied across 2D, 3D or more dimensions. A more detailed overview of the module is available in the
&lt;a href="https://docs.scipy.org/doc/scipy/reference/tutorial/ndimage.html"&gt;SciPy ndimage tutorial&lt;/a&gt;. SciPy's image functions are also used by downstream libraries such as &lt;a href="https://scikit-image.org"&gt;scikit-image&lt;/a&gt; to implement higher-level algorithms for things like image restoration, segmentation and registration.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://labs.quansight.org/blog/2021/01/scipy-ndimage-interpolation/"&gt;Read more…&lt;/a&gt; (5 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Labs</category><category>Open-Source</category><category>Python</category><category>SciPy</category><guid>https://labs.quansight.org/blog/2021/01/scipy-ndimage-interpolation/</guid><pubDate>Fri, 22 Jan 2021 14:00:00 GMT</pubDate></item><item><title>Introduction to Design in Open Source</title><link>https://labs.quansight.org/blog/2020/11/introduction-to-design-in-open-source/</link><dc:creator>Tim George, Isabela Presedo-Floyd</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;em&gt;This blog post is a conversation. Portions lead by Tim George are marked with
&lt;/em&gt;&lt;em&gt;TG&lt;/em&gt;&lt;em&gt;, and those lead by Isabela Presedo-Floyd are marked with &lt;/em&gt;&lt;em&gt;IPF&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TG:&lt;/strong&gt; When I speak with other designers, one common theme I see concerning why
they chose this career path is they want to make a difference in the world. We
design because we imagine a better world and we want to help make it real. Part
of the reason we design as a career is we're unable to go through life without
designing; we're always thinking about how things are and how they could be
better. This ethos also exists in many open-source communities. It seems like it
ought to be an ideal match.&lt;/p&gt;
&lt;p&gt;So what's the disconnect? I'm still exploring that myself, but after a few years
in open source I want to share my observations, experiences, and hope for a
stronger collaboration between design and development. I don't think I have a
complete solution, and some days I'm not even sure I grasp the entire problem.
What I hope is to say that which often goes unsaid in these spaces: design and
development skills in open source coexist precariously.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://labs.quansight.org/blog/2020/11/introduction-to-design-in-open-source/"&gt;Read more…&lt;/a&gt; (10 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>design</category><category>Open-Source</category><category>User Experience</category><category>UX</category><guid>https://labs.quansight.org/blog/2020/11/introduction-to-design-in-open-source/</guid><pubDate>Wed, 18 Nov 2020 05:00:30 GMT</pubDate></item></channel></rss>