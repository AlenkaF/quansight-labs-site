<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Quansight Labs (Posts by Sameer Deshmukh)</title><link>https://labs.quansight.org/</link><description></description><atom:link href="https://labs.quansight.org/authors/sameer-deshmukh.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2021 &lt;a href="mailto:info@quansight.com"&gt;Quansight Labs Team&lt;/a&gt; </copyright><lastBuildDate>Mon, 06 Sep 2021 16:34:10 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>PyTorch TensorIterator Internals</title><link>https://labs.quansight.org/blog/2020/04/pytorch-tensoriterator-internals/</link><dc:creator>Sameer Deshmukh</dc:creator><description>&lt;div&gt;&lt;p class="alert alert-warning"&gt;The history section of this post is still relevant, but &lt;code&gt;TensorIterator&lt;/code&gt;'s
interface has changed significantly. For an update on the new API, please check
out &lt;a href="https://labs.quansight.org/blog/2021/04/pytorch-tensoriterator-internals-update/index.html"&gt;this new blog
post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;PyTorch is one of the leading frameworks for deep learning. Its core data
structure is &lt;code&gt;Tensor&lt;/code&gt;, a multi-dimensional array implementation with many
advanced features like auto-differentiation. PyTorch is a massive
codebase (approx. &lt;a href="https://www.openhub.net/p/pytorch"&gt;a million lines&lt;/a&gt; of
C++, Python and CUDA code), and having a method for iterating over tensors in a
very efficient manner that is independent of data type, dimension, striding and
hardware is a critical feature that can lead to a very massive simplification
of the codebase and make distributed development much faster and smoother. The
&lt;a href="https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/TensorIterator.cpp"&gt;&lt;code&gt;TensorIterator&lt;/code&gt;&lt;/a&gt;
C++ class within PyTorch is a complex yet useful class that is used for
iterating over the elements of a tensor over any dimension and implicitly
parallelizing various operations in a device independent manner.&lt;/p&gt;
&lt;p&gt;It does this through a C++ API that is independent of type and device of the
tensor, freeing the programmer of having to worry about the datatype or device
when writing iteration logic for PyTorch tensors. For those coming from the
NumPy universe, &lt;code&gt;NpyIter&lt;/code&gt; is a close cousin of &lt;code&gt;TensorIterator&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This post is a deep dive into how &lt;code&gt;TensorIterator&lt;/code&gt; works, and is an essential
part of learning to contribute to the PyTorch codebase since iterations over
tensors in the C++ codebase are extremely commonplace. This post is aimed at
someone who wants to contribute to PyTorch, and you should at least be familiar
with some of the basic terminologies of the PyTorch codebase that can be found
in Edward Yang's excellent &lt;a href="http://blog.ezyang.com/2019/05/pytorch-internals"&gt;blog post&lt;/a&gt;
on PyTorch internals.  Although &lt;code&gt;TensorIterator&lt;/code&gt; can be used for both CPUs and
accelerators, this post has been written keeping in mind usage on the CPU.
Although there can be some dissimilarities between the two, the overall
concepts are the same.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://labs.quansight.org/blog/2020/04/pytorch-tensoriterator-internals/"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>C++</category><category>PyTorch</category><guid>https://labs.quansight.org/blog/2020/04/pytorch-tensoriterator-internals/</guid><pubDate>Mon, 13 Apr 2020 15:39:56 GMT</pubDate></item><item><title>Ruby wrappers for the XND project</title><link>https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/</link><dc:creator>Sameer Deshmukh</dc:creator><description>&lt;div&gt;&lt;!-- markdown-toc start - Don't edit this section. Run M-x markdown-toc-generate-toc again --&gt;

&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#ndtypes"&gt;Ndtypes&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#usage"&gt;Usage&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#basic-initialization"&gt;Basic initialization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#concrete-vs-abstract-types"&gt;Concrete Vs. Abstract Types&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#typedefs"&gt;Typedefs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#usage-via-the-c-api"&gt;Usage via The C API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#implementation"&gt;Implementation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#xnd"&gt;Xnd&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#basic-usage"&gt;Basic Usage&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#data-type-support"&gt;Data Type Support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#missing-values"&gt;Missing Values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#usage-via-the-c-api"&gt;Usage via The C API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#implementation"&gt;Implementation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#gumath"&gt;Gumath&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#usage"&gt;Usage&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#usage-via-the-c-api"&gt;Usage via The C API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#implementation"&gt;Implementation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#automatic-kernel-generation"&gt;Automatic Kernel Generation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/#conclusion-and-future-work"&gt;Conclusion and Future Work&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- markdown-toc end --&gt;

&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Lack of stable and reliable scientific computing software has been a persistent problem
for the Ruby community, making it hard for enthusiastic Ruby developers to use Ruby in
everything from their web applications to their data analysis projects. One of the most important
components of any successful scientific software stack is a well maintained and flexible
array computation library that can act as a fast and simple way of storing in-memory data
and interfacing it with various fast and battle-tested libraries like LAPACK and BLAS.&lt;/p&gt;
&lt;p&gt;Various projects have attempted to make such libraries in the past (and some are still thriving
and maintained). Some of the notable ones are &lt;a href="https://github.com/ruby-numo"&gt;numo&lt;/a&gt;, &lt;a href="https://github.com/SciRuby/nmatrix"&gt;nmatrix&lt;/a&gt;, and more recently, &lt;a href="https://github.com/SciRuby/numruby"&gt;numruby&lt;/a&gt;.
These projects attempt to provide a simple Ruby-like API for creating and manipulating arrays
of various types. All of them are able to easily interface with libraries like ATLAS, FFTW
and LAPACK.&lt;/p&gt;
&lt;p&gt;However, all of the above projects fall short in two major aspects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lack of extensibility to adapt to modern use cases (read Machine Learning).&lt;/li&gt;
&lt;li&gt;Lack of a critical mass of developers to maintain a robust and fast array library.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first problem is mainly due to the fact that they do not support very robust type systems.
The available data types are limited and are hard to extend to more complex uses. Modern use cases like
Machine Learning require a more robust type system (i.e. defining array shapes of arbitrary dimension on multiple devices), as has been demonstrated by the tensor
implementations of various frameworks like Tensorflow and PyTorch.&lt;/p&gt;
&lt;p&gt;The second problem is due to the fact that all of the aforementioned projects are community
efforts that are maintained part-time by developers simply out of a sense of purpose and
passion. Sustaining such complex projects for extended periods of time without expectation
of any support is simply unfeasible even for the most driven engineers.&lt;/p&gt;
&lt;p&gt;This is where the XND project comes in. The &lt;a href="https://xnd.io/"&gt;XND project&lt;/a&gt; is a project for
building a common library that is able to meet the needs of the various data analysis and
machine learning frameworks that have had to build their own array objects and programming 
languages. It is built with the premise of extending arrays with new types and various 
device types (CPUs, GPUs etc.) without loss of performance and ease of use.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/"&gt;Read more…&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><guid>https://labs.quansight.org/blog/2019/09/ruby-wrappers-for-the-xnd-project/</guid><pubDate>Sun, 15 Sep 2019 05:32:00 GMT</pubDate></item></channel></rss>